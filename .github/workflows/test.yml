name: Test Suite

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - security
          - load
  workflow_call:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: string

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  AWS_REGION: 'us-east-1'

jobs:
  setup:
    name: Setup and Validation
    runs-on: ubuntu-latest
    outputs:
      should_run_unit: ${{ steps.determine.outputs.run_unit }}
      should_run_integration: ${{ steps.determine.outputs.run_integration }}
      should_run_e2e: ${{ steps.determine.outputs.run_e2e }}
      should_run_security: ${{ steps.determine.outputs.run_security }}
      should_run_load: ${{ steps.determine.outputs.run_load }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine test suites to run
        id: determine
        run: |
          TEST_SUITE="${{ github.event.inputs.test_suite || 'all' }}"
          
          if [[ "$TEST_SUITE" == "all" ]]; then
            echo "run_unit=true" >> $GITHUB_OUTPUT
            echo "run_integration=true" >> $GITHUB_OUTPUT
            echo "run_e2e=true" >> $GITHUB_OUTPUT
            echo "run_security=true" >> $GITHUB_OUTPUT
            echo "run_load=false" >> $GITHUB_OUTPUT  # Load tests only on explicit request
          else
            echo "run_unit=$([[ $TEST_SUITE == *unit* ]] && echo true || echo false)" >> $GITHUB_OUTPUT
            echo "run_integration=$([[ $TEST_SUITE == *integration* ]] && echo true || echo false)" >> $GITHUB_OUTPUT
            echo "run_e2e=$([[ $TEST_SUITE == *e2e* ]] && echo true || echo false)" >> $GITHUB_OUTPUT
            echo "run_security=$([[ $TEST_SUITE == *security* ]] && echo true || echo false)" >> $GITHUB_OUTPUT
            echo "run_load=$([[ $TEST_SUITE == *load* ]] && echo true || echo false)" >> $GITHUB_OUTPUT
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          cd frontend && npm ci

      - name: Validate package.json files
        run: |
          npm audit --audit-level moderate
          cd frontend && npm audit --audit-level moderate

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            frontend/node_modules
            node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_unit == 'true'
    strategy:
      matrix:
        test-group: [backend, frontend, lambda]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          cd frontend && npm ci

      - name: Run unit tests - Backend
        if: matrix.test-group == 'backend'
        run: |
          npm test -- --coverage --testPathPattern=src/.*\.test\.(js|ts)$
        env:
          NODE_ENV: test

      - name: Run unit tests - Frontend
        if: matrix.test-group == 'frontend'
        run: |
          cd frontend
          npm test -- --coverage --watchAll=false
        env:
          NODE_ENV: test

      - name: Run unit tests - Lambda
        if: matrix.test-group == 'lambda'
        run: |
          npm test -- --coverage --testPathPattern=lambda/.*\.test\.(js|ts)$
        env:
          NODE_ENV: test

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          directory: ./coverage
          flags: ${{ matrix.test-group }}
          name: ${{ matrix.test-group }}-coverage

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_integration == 'true'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: curriculum_alignment_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test database
        run: |
          cd scripts/migrations
          PGPASSWORD=test_password psql -h localhost -U test_user -d curriculum_alignment_test -f 001_initial_schema.sql
          PGPASSWORD=test_password psql -h localhost -U test_user -d curriculum_alignment_test -f 002_indexes_and_performance.sql

      - name: Run integration tests
        run: |
          cd tests/integration
          npm test
        env:
          NODE_ENV: test
          DATABASE_URL: postgres://test_user:test_password@localhost:5432/curriculum_alignment_test

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: tests/integration/results/

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_e2e == 'true'
    strategy:
      matrix:
        browser: [chromium, firefox]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          cd frontend && npm ci

      - name: Install Playwright browsers
        run: |
          cd tests/e2e
          npx playwright install ${{ matrix.browser }}

      - name: Build frontend
        run: |
          cd frontend
          npm run build

      - name: Start test environment
        run: |
          # Start mock backend
          npm run test:server &
          # Start frontend dev server
          cd frontend && npm run preview &
          # Wait for services to be ready
          timeout 60 bash -c 'until curl -f http://localhost:3000; do sleep 2; done'
          timeout 60 bash -c 'until curl -f http://localhost:8080; do sleep 2; done'

      - name: Run E2E tests
        run: |
          cd tests/e2e
          npx playwright test --project=${{ matrix.browser }}
        env:
          BASE_URL: http://localhost:3000
          API_URL: http://localhost:8080

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}
          path: |
            tests/e2e/test-results/
            tests/e2e/playwright-report/

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security tests
        run: |
          cd tests/security
          ./run-security-tests.sh all --base-url http://localhost:3000 --environment test
        env:
          NODE_ENV: test
          DISABLE_REAL_AUTH: true
          MOCK_EXTERNAL_APIS: true

      - name: Run dependency audit
        run: |
          npm audit --audit-level high
          cd frontend && npm audit --audit-level high

      - name: Run SAST with CodeQL
        uses: github/codeql-action/init@v2
        with:
          languages: javascript, typescript

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v2

      - name: Upload security report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: tests/security/results/

  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_load == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Start test environment
        run: |
          npm run test:server &
          timeout 60 bash -c 'until curl -f http://localhost:8080; do sleep 2; done'

      - name: Run load tests
        run: |
          cd tests/load
          npm test
        env:
          BASE_URL: http://localhost:8080
          CONCURRENT_USERS: 10
          TEST_DURATION: 60s

      - name: Upload load test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: load-test-results
          path: tests/load/results/

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, security-tests]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test artifacts
        uses: actions/download-artifact@v3

      - name: Evaluate quality gate
        run: |
          echo "Evaluating test results..."
          
          # Check if critical tests passed
          UNIT_SUCCESS=${{ needs.unit-tests.result == 'success' }}
          INTEGRATION_SUCCESS=${{ needs.integration-tests.result == 'success' }}
          E2E_SUCCESS=${{ needs.e2e-tests.result == 'success' }}
          SECURITY_SUCCESS=${{ needs.security-tests.result == 'success' }}
          
          echo "Unit tests: $UNIT_SUCCESS"
          echo "Integration tests: $INTEGRATION_SUCCESS"
          echo "E2E tests: $E2E_SUCCESS"
          echo "Security tests: $SECURITY_SUCCESS"
          
          # Quality gate logic
          if [[ "$UNIT_SUCCESS" == "true" && "$INTEGRATION_SUCCESS" == "true" ]]; then
            echo "âœ… Quality gate passed - Core functionality verified"
            echo "QUALITY_GATE=passed" >> $GITHUB_ENV
          else
            echo "âŒ Quality gate failed - Critical tests failed"
            echo "QUALITY_GATE=failed" >> $GITHUB_ENV
            exit 1
          fi

      - name: Generate test summary
        run: |
          cat > test-summary.md << 'EOF'
          # Test Results Summary
          
          ## Test Suite Status
          - **Unit Tests**: ${{ needs.unit-tests.result }}
          - **Integration Tests**: ${{ needs.integration-tests.result }}
          - **E2E Tests**: ${{ needs.e2e-tests.result }}
          - **Security Tests**: ${{ needs.security-tests.result }}
          
          ## Quality Gate: ${{ env.QUALITY_GATE }}
          
          Generated at: $(date -u)
          EOF

      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const testSummary = fs.readFileSync('test-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testSummary
            });

  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: always()
    steps:
      - name: Notify success
        if: needs.quality-gate.result == 'success'
        run: |
          echo "ğŸ‰ All tests passed! Ready for deployment."

      - name: Notify failure
        if: needs.quality-gate.result == 'failure'
        run: |
          echo "âŒ Tests failed. Deployment blocked."
          exit 1